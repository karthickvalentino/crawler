### Issue Title: Support Multiple LLMs for Vector Embeddings (Default: llama3.2:latest with Ollama)\n\n#### Description:\nEnable the AI crawler to generate vector embeddings using multiple Large Language Models (LLMs). The default model will be llama3.2:latest via Ollama. Add support for other LLMs such as OpenAI, Gemini, and any additional models as needed. The system should allow selecting the embedding model per task or configuration, providing flexibility and extensibility for future LLMs.\n\n#### Acceptance Criteria:\n- The crawler can generate vector embeddings using llama3.2:latest (Ollama) by default.\n- The system supports switching between different LLMs (e.g., OpenAI, Gemini) for embedding generation.\n- Configuration is available to select the desired LLM for vector embeddings.\n- Documentation is updated to describe how to add new LLM support and configure the embedding model.\n- Tests validate embeddings generation for each supported LLM.\n\n#### Priority: Medium\n#### Assignee: karthickvalentino